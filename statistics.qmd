---
title: "The Evidence"
subtitle: "Mathematical Proof Behind the Patterns"
---

```{r}
#| label: setup
#| include: false

# Set library path and load packages
.libPaths(Sys.getenv("R_LIBS_USER"))
library(tidyverse)
library(knitr)
library(kableExtra)

# Load the data
source("R/load_data.R")

# Pre-calculate for inline R
total_students <- sum(school_data$nb_students, na.rm = TRUE)
mean_rate <- round(mean(school_data$success_rate, na.rm = TRUE), 1)
median_rate <- round(median(school_data$success_rate, na.rm = TRUE), 1)
```

## The Scientific Investigation Begins {.unnumbered}

::: {.callout-important appearance="simple"}
## üî¨ Our Mission
We've seen the patterns in the visualizations. Now we need to answer: **Are these differences REAL or just random chance?**
:::

In science, we don't just rely on what our eyes see. We test our observations mathematically to separate **signal from noise**.

---

## üìä Act 1: Understanding Our Data {.unnumbered}

### The Vital Statistics

Before testing hypotheses, let's understand the fundamental characteristics of our data.

```{r}
#| label: vital-stats

# Comprehensive statistics
stats <- school_data %>%
  summarise(
    `üìà Mean Success Rate` = paste0(round(mean(success_rate, na.rm = TRUE), 2), "%"),
    `üìä Median Success Rate` = paste0(round(median(success_rate, na.rm = TRUE), 2), "%"),
    `üìâ Standard Deviation` = paste0(round(sd(success_rate, na.rm = TRUE), 2), "%"),
    `‚¨áÔ∏è Minimum` = paste0(min(success_rate, na.rm = TRUE), "%"),
    `‚¨ÜÔ∏è Maximum` = paste0(max(success_rate, na.rm = TRUE), "%"),
    `üìè Range` = paste0(round(max(success_rate, na.rm = TRUE) - min(success_rate, na.rm = TRUE), 2), " points"),
    `üéØ IQR` = paste0(round(IQR(success_rate, na.rm = TRUE), 2), " points")
  )

stats %>%
  pivot_longer(everything(), names_to = "Measure", values_to = "Value") %>%
  kable(caption = "üìã The Numbers That Define Our Dataset") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE) %>%
  column_spec(1, bold = TRUE, width = "15em") %>%
  column_spec(2, color = "#2c3e50", bold = TRUE)
```

::: {.callout-note}
## üí° What This Reveals
The **mean (`r mean_rate`%)** is slightly lower than the **median (`r median_rate`%)**, confirming our earlier observation: the distribution is **left-skewed**. Most schools perform well, but a few underperformers pull the average down.
:::

---

## üß™ Act 2: The Normality Question {.unnumbered}

::: {.callout-tip appearance="simple"}
## ‚ùì Why Does This Matter?
Many statistical tests assume data follows a "normal" (bell-shaped) distribution. If our data isn't normal, we need to use different methods.
:::

### Visual Evidence: The Q-Q Plot

```{r}
#| label: fig-qq
#| fig-cap: "Does our data follow the theoretical normal distribution?"
#| fig-width: 10
#| fig-height: 6

ggplot(school_data, aes(sample = success_rate)) +
  stat_qq(color = "#3498db", alpha = 0.5, size = 2) +
  stat_qq_line(color = "#e74c3c", linewidth = 1.5) +
  annotate("label", x = -2, y = 95, 
           label = "Points should follow\nthe red line if normal", 
           fill = "#fff3cd", color = "#856404", size = 4) +
  labs(
    title = "Q-Q PLOT: Testing for Normality",
    subtitle = "Deviation from the line = departure from normality",
    x = "Theoretical Quantiles",
    y = "Sample Quantiles (Success Rate %)"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 20, color = "#2c3e50"),
    plot.subtitle = element_text(hjust = 0.5, color = "#7f8c8d")
  )
```

### Mathematical Evidence: Shapiro-Wilk Test

```{r}
#| label: shapiro

set.seed(42)
sample_size <- min(5000, nrow(school_data))
sample_data <- sample(school_data$success_rate, sample_size)
shapiro_result <- shapiro.test(sample_data)

cat("‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n")
cat("‚ïë           SHAPIRO-WILK NORMALITY TEST                        ‚ïë\n")
cat("‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n")
cat(paste0("‚ïë  W statistic:  ", sprintf("%.6f", shapiro_result$statistic), "                                 ‚ïë\n"))
cat(paste0("‚ïë  p-value:      ", sprintf("%.2e", shapiro_result$p.value), " (extremely small!)           ‚ïë\n"))
cat("‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n")

if(shapiro_result$p.value < 0.05) {
  cat("‚ïë  üî¥ VERDICT: Data is NOT normally distributed                ‚ïë\n")
  cat("‚ïë     ‚Üí We must use non-parametric tests                       ‚ïë\n")
} else {
  cat("‚ïë  üü¢ VERDICT: Data appears normally distributed               ‚ïë\n")
}
cat("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n")
```

::: {.callout-warning}
## ‚ö†Ô∏è Important Implication
Since our data is **not normal**, we'll use **non-parametric tests** (like Kruskal-Wallis) that don't assume normality. This ensures our conclusions are statistically valid.
:::

---

## üîç Act 3: The Big Question - Regional Differences {.unnumbered}

::: {.callout-important appearance="simple"}
## üéØ Hypothesis Under Investigation
**Do success rates TRULY differ between governorates, or is what we saw just random variation?**

- **H‚ÇÄ (Null)**: All governorates have the same median success rate
- **H‚ÇÅ (Alternative)**: At least one governorate differs significantly
:::

### The Kruskal-Wallis Test

```{r}
#| label: kruskal

kruskal_result <- kruskal.test(success_rate ~ governorate, data = school_data)

cat("\n")
cat("‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n")
cat("‚ïë         KRUSKAL-WALLIS RANK SUM TEST                         ‚ïë\n")
cat("‚ïë         (Non-parametric alternative to ANOVA)                ‚ïë\n")
cat("‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n")
cat(paste0("‚ïë  Chi-squared (œá¬≤):  ", sprintf("%.2f", kruskal_result$statistic), "                             ‚ïë\n"))
cat(paste0("‚ïë  Degrees of freedom: ", kruskal_result$parameter, "                                    ‚ïë\n"))
cat(paste0("‚ïë  p-value:           ", sprintf("%.2e", kruskal_result$p.value), "                            ‚ïë\n"))
cat("‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n")

if(kruskal_result$p.value < 0.001) {
  cat("‚ïë  üî¥ VERDICT: HIGHLY SIGNIFICANT (p < 0.001)                  ‚ïë\n")
  cat("‚ïë                                                              ‚ïë\n")
  cat("‚ïë  ‚û°Ô∏è  Regional differences are REAL, not random chance        ‚ïë\n")
  cat("‚ïë  ‚û°Ô∏è  Where a student studies DOES matter                     ‚ïë\n")
}
cat("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n")
```

```{r}
#| label: fig-evidence-boxplot
#| fig-cap: "Visual Evidence: Box plots show clear differences between governorates"
#| fig-width: 14
#| fig-height: 8

gov_order <- school_data %>%
  group_by(governorate) %>%
  summarise(med = median(success_rate, na.rm = TRUE)) %>%
  arrange(desc(med)) %>%
  pull(governorate)

school_data %>%
  filter(!is.na(governorate)) %>%
  mutate(governorate = factor(governorate, levels = gov_order)) %>%
  ggplot(aes(x = governorate, y = success_rate, fill = governorate)) +
  geom_boxplot(show.legend = FALSE, alpha = 0.7, outlier.alpha = 0.3) +
  geom_hline(yintercept = median(school_data$success_rate, na.rm = TRUE), 
             color = "#e74c3c", linetype = "dashed", linewidth = 1) +
  annotate("text", x = 20, y = median(school_data$success_rate) + 3, 
           label = "National Median", color = "#e74c3c", fontface = "bold") +
  scale_fill_viridis_d(option = "plasma") +
  labs(
    title = "SUCCESS RATE DISTRIBUTION BY GOVERNORATE",
    subtitle = "The spread tells the story - some regions are consistently better",
    x = "Governorate",
    y = "Success Rate (%)"
  ) +
  coord_flip() +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 18),
    plot.subtitle = element_text(hjust = 0.5, color = "#7f8c8d")
  )
```

---

## üìà Act 4: The Correlation Mystery {.unnumbered}

::: {.callout-note appearance="simple"}
## ü§î A Common Assumption
Many believe that **smaller classes = better results**. Let's test this with our data.
:::

### Does Class Size Affect Success?

```{r}
#| label: correlation

cor_result <- cor.test(school_data$nb_students, school_data$success_rate)

cat("\n")
cat("‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n")
cat("‚ïë         PEARSON CORRELATION TEST                             ‚ïë\n")
cat("‚ïë         Class Size vs. Success Rate                          ‚ïë\n")
cat("‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n")
cat(paste0("‚ïë  Correlation (r):  ", sprintf("%.4f", cor_result$estimate), "                               ‚ïë\n"))
cat(paste0("‚ïë  p-value:          ", sprintf("%.2e", cor_result$p.value), "                             ‚ïë\n"))
cat(paste0("‚ïë  95% CI:           [", sprintf("%.4f", cor_result$conf.int[1]), ", ", sprintf("%.4f", cor_result$conf.int[2]), "]                   ‚ïë\n"))
cat("‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n")

r_val <- cor_result$estimate
if(abs(r_val) < 0.1) {
  strength <- "virtually no"
} else if(abs(r_val) < 0.3) {
  strength <- "a weak"
} else if(abs(r_val) < 0.5) {
  strength <- "a moderate"
} else {
  strength <- "a strong"
}

direction <- ifelse(r_val < 0, "negative", "positive")

cat(paste0("‚ïë  üìä INTERPRETATION: There is ", strength, " ", direction, " correlation     ‚ïë\n"))
cat("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n")
```

```{r}
#| label: fig-scatter-story
#| fig-cap: "The Relationship Between Class Size and Success"
#| fig-width: 12
#| fig-height: 7

ggplot(school_data, aes(x = nb_students, y = success_rate)) +
  geom_point(alpha = 0.2, color = "#3498db", size = 2) +
  geom_smooth(method = "lm", color = "#e74c3c", fill = "#e74c3c", alpha = 0.2, linewidth = 1.5) +
  annotate("label", x = max(school_data$nb_students) * 0.7, y = 30, 
           label = paste0("r = ", round(cor_result$estimate, 3), "\n(", 
                          ifelse(abs(cor_result$estimate) < 0.1, "Very Weak", "Weak"), " relationship)"),
           fill = "#fff3cd", color = "#856404", size = 5, fontface = "bold") +
  labs(
    title = "CLASS SIZE vs. SUCCESS RATE",
    subtitle = "Surprising finding: Class size barely matters!",
    x = "Number of Students",
    y = "Success Rate (%)"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 20, color = "#2c3e50"),
    plot.subtitle = element_text(hjust = 0.5, size = 14, color = "#7f8c8d")
  )
```

::: {.callout-tip}
## üéØ Surprising Insight!
Contrary to popular belief, **class size has almost NO effect on success rates** in our data. Other factors (teacher quality, resources, regional support) likely play much bigger roles.
:::

---

## üìä Act 5: Modeling Success {.unnumbered}

### What Predicts Success? A Regression Analysis

```{r}
#| label: regression-model

# Build model with governorate
model <- lm(success_rate ~ nb_students + governorate, data = school_data)
model_summary <- summary(model)

cat("\n")
cat("‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n")
cat("‚ïë         MULTIPLE REGRESSION MODEL                            ‚ïë\n")
cat("‚ïë         Success Rate ~ Class Size + Governorate              ‚ïë\n")
cat("‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n")
cat(paste0("‚ïë  R¬≤ (variance explained):    ", sprintf("%.1f%%", model_summary$r.squared * 100), "                         ‚ïë\n"))
cat(paste0("‚ïë  Adjusted R¬≤:                ", sprintf("%.1f%%", model_summary$adj.r.squared * 100), "                         ‚ïë\n"))
cat(paste0("‚ïë  F-statistic:                ", sprintf("%.2f", model_summary$fstatistic[1]), "                          ‚ïë\n"))
cat("‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n")
cat("‚ïë  üìä INTERPRETATION:                                          ‚ïë\n")
cat(paste0("‚ïë  ‚Üí Governorate alone explains ~", sprintf("%.0f%%", model_summary$r.squared * 100), " of success variation   ‚ïë\n"))
cat("‚ïë  ‚Üí The remaining variance comes from other factors           ‚ïë\n")
cat("‚ïë    (teacher quality, resources, student background, etc.)    ‚ïë\n")
cat("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n")
```

### Residual Analysis: Is Our Model Reliable?

```{r}
#| label: fig-residuals
#| fig-cap: "Model Diagnostics: Checking for patterns in residuals"
#| fig-width: 12
#| fig-height: 6

residual_data <- data.frame(
  fitted = fitted(model),
  residuals = residuals(model)
)

ggplot(residual_data, aes(x = fitted, y = residuals)) +
  geom_point(alpha = 0.2, color = "#3498db") +
  geom_hline(yintercept = 0, color = "#e74c3c", linewidth = 1.5, linetype = "dashed") +
  geom_smooth(method = "loess", color = "#27ae60", se = FALSE, linewidth = 1) +
  annotate("label", x = 70, y = max(residual_data$residuals) * 0.8, 
           label = "Green line should be flat\nif model is good", 
           fill = "#d4edda", color = "#155724", size = 4) +
  labs(
    title = "RESIDUAL ANALYSIS",
    subtitle = "Looking for patterns that might indicate model problems",
    x = "Fitted Values (Predicted Success Rate)",
    y = "Residuals (Actual - Predicted)"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 18),
    plot.subtitle = element_text(hjust = 0.5, color = "#7f8c8d")
  )
```

---

## üéØ The Final Verdict {.unnumbered}

```{r}
#| label: final-summary

findings <- data.frame(
  Question = c(
    "üó∫Ô∏è Do regions differ in success?",
    "üìè Does class size matter?",
    "üìä Is data normally distributed?",
    "üìà What explains success variation?",
    "üéì Overall success rate"
  ),
  Answer = c(
    "YES - Highly significant differences (p < 0.001)",
    "BARELY - Very weak correlation (r ‚âà -0.09)",
    "NO - Left-skewed distribution",
    paste0("~", round(model_summary$r.squared * 100, 0), "% explained by location"),
    paste0(round(mean(school_data$success_rate, na.rm = TRUE), 1), "% average")
  ),
  Implication = c(
    "Location affects educational outcomes",
    "Focus on quality, not just class size",
    "Use non-parametric statistical methods",
    "Other factors (teachers, resources) matter more",
    "Tunisia's education system performs reasonably well"
  )
)

findings %>%
  kable(caption = "üìã Summary of Statistical Findings") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = TRUE) %>%
  column_spec(1, bold = TRUE, width = "20em") %>%
  column_spec(2, color = "#2c3e50", bold = TRUE) %>%
  column_spec(3, color = "#7f8c8d", italic = TRUE)
```

---

## üìñ The Story's Moral {.unnumbered}

::: {.callout-important}
## üí° Key Takeaways for Policymakers

1. **Regional Investment Matters**: The significant differences between governorates suggest that targeted investment in underperforming regions could have a major impact.

2. **Class Size is Overrated**: Instead of focusing on reducing class sizes, resources might be better spent on teacher training and educational materials.

3. **Address the 20%**: While 80% of students succeed, the 20% who struggle deserve focused attention and support programs.

4. **Data-Driven Decisions**: This analysis shows how data can reveal surprising insights that contradict common assumptions.
:::

---

::: {.callout-tip}
## üîÑ Back to Visualizations
Return to **[The Story of Success](visualizations.qmd)** to see these findings illustrated graphically.
:::
